"""Fetching IDs for files and datasets."""

from pathlib import Path
from typing import Dict, Union
from uuid import uuid4
from os import environ
from datetime import date
import shortuuid
import re

from .logger import LOG
from ..config import CONFIG_INFO

from httpx import Headers, AsyncClient


def generate_dataset_id(user: str, inbox_path: str, ns: Union[str, None] = None) -> str:
    """Map accession ID to dataset.

    Generate dataset id based on folder or user.
    We keep the email domain as users might have same name on different domains
    and that could indicate different datasets.
    """
    file_path = Path(inbox_path)
    file_path_parts = file_path.parts
    dataset = ""
    ns = ns if ns else "urn:neic:"

    # add trailing slash if it does not exist
    if ns.startswith(("http://", "https://")):
        if ns[len(ns) - 1] != "/":
            ns = ns + "/"
    # if a file it is submited in the root directory the dataset
    # is then ns:<username>
    # otherwise we take the root directory and construct the path
    # ns:<username>-<root_dir>
    if len(file_path_parts) <= 2:
        dataset = f"{ns}{user}"
    else:
        # if it is / then we take the next value
        dataset = f"{ns}{user}-{file_path_parts[1]}"

    LOG.debug(f"generated dataset id as: {dataset}")

    return dataset


def generate_accession_id() -> str:
    """Generate Stable ID."""
    accessionID = uuid4()

    urn = accessionID.urn
    LOG.debug(f"generated accession id as: {urn}")
    return urn


class DOIHandler:
    """Handler for DOI registration at Datacite.

    The workflow consists of create a short uuid based on user and folder/root directory
    where the file was uploaded. Based on this information we group files into dataset
    It is recommended that first step is to create a draft DOI as it can later be removed easier,
    in case of an error.

    ``create_draft_doi`` generates the identifier using a 10 chars shortuuid from, which guarantee
    uniqueness based on the way we generate the dataset ID.

    The ``set_doi_state`` can also be used to create a draft DOI, however its use is dependent on generating
    a doi_suffix externally.
    """

    def __init__(self) -> None:
        """Define DOI credentials and config."""
        self.doi_prefix = environ.get("DOI_PREFIX", "")
        self.doi_api = environ.get("DOI_API", "")
        self.doi_user = environ.get("DOI_USER", "")
        self.doi_key = environ.get("DOI_KEY", "")
        self.ns_url = f"https://doi.org/{self.doi_prefix}"

    async def create_draft_doi(self, user: str, inbox_path: str) -> Union[Dict, None]:
        """Create an auto-generated draft DOI.

        We are using just the prefix for the DOI so that it will be autogenerated.
        """
        dataset = generate_dataset_id(user, inbox_path, self.ns_url)
        suffix = shortuuid.uuid(name=dataset)[:10]
        doi_suffix = f"{suffix[:4]}-{suffix[4:]}"

        headers = Headers({"Content-Type": "application/json"})
        draft_doi_payload = {"data": {"type": "dois", "attributes": {"doi": f"{self.doi_prefix}/{doi_suffix}"}}}
        async with AsyncClient() as client:
            response = await client.post(
                self.doi_api, auth=(self.doi_user, self.doi_key), json=draft_doi_payload, headers=headers
            )
        draft_resp = response.json()

        doi_data = None
        if response.status_code == 200:
            LOG.debug(f"DOI draft created and response was: {draft_resp}")
            LOG.info(f"DOI draft created with doi: {draft_resp['data']['attributes']['doi']}.")
            doi_data = {
                "suffix": draft_resp["data"]["attributes"]["suffix"],
                "fullDOI": draft_resp["data"]["attributes"]["doi"],
            }
        else:
            doi_data = self._check_errors(draft_resp, doi_suffix)

        return doi_data

    async def set_doi_state(self, state: str, doi_suffix: str) -> Union[Dict, None]:
        """Set DOI and associated metadata.

        :param state: can be publish, register or hide, or even draft if preferred .
        :param doi: DOI to do operations on.
        """
        publish_data_payload = {
            "data": {
                "id": f"{self.doi_prefix}/{doi_suffix}",
                "type": "dois",
                "attributes": {
                    "event": state,
                    "doi": f"{self.doi_prefix}/{doi_suffix}",
                    "titles": [{"title": f"{CONFIG_INFO['datacite']['titlePrefix']}", "lang": "en"}],
                    "publisher": CONFIG_INFO["datacite"]["publisher"],
                    # will be current year
                    "publicationYear": date.today().year,
                    # resource type is predefined as dataset
                    "types": {
                        "ris": "DATA",
                        "bibtex": "misc",
                        "citeproc": "dataset",
                        "schemaOrg": "Dataset",
                        "resourceTypeGeneral": "Dataset",
                    },
                    "subjects": CONFIG_INFO["datacite"]["subjects"],
                    "url": CONFIG_INFO["datacite"]["resourceURL"],
                    "schemaVersion": "https://schema.datacite.org/meta/kernel-4.3/",
                },
            }
        }
        headers = Headers({"Content-Type": "application/json"})
        async with AsyncClient() as client:
            response = await client.post(
                self.doi_api, auth=(self.doi_user, self.doi_key), json=publish_data_payload, headers=headers
            )
        publish_resp = response.json()
        doi_data = None
        if response.status_code == 200:
            LOG.debug(f"DOI created with state: {state} and response was: {publish_resp}")
            LOG.info(f"DOI created with doi: {publish_resp['data']['attributes']['doi']} with state {state}.")
            doi_data = {
                "suffix": publish_resp["data"]["attributes"]["suffix"],
                "fullDOI": publish_resp["data"]["attributes"]["doi"],
            }
        else:
            LOG.error(f"DOI API request failed with code: {response.status_code}")
            doi_data = self._check_errors(publish_resp, doi_suffix)

        return doi_data

    def _check_errors(self, response: Dict, doi_suffix: str) -> Union[Dict, None]:
        errors_resp = response["errors"]
        doi_data = None
        if len(errors_resp) == 1:
            error_msg = errors_resp[0]["title"] if "title" in errors_resp[0] else errors_resp[0]["detail"]
            if errors_resp[0]["source"] == "doi" and error_msg == "This DOI has already been taken":
                LOG.info("DOI already taken, we will associate the submission to this doi dataset.")
                doi_data = {
                    "suffix": doi_suffix,
                    "fullDOI": f"{self.doi_prefix}/{doi_suffix}",
                }
            else:
                LOG.error(f"Error occurred: {errors_resp}")
                raise Exception(f"{error_msg}")
        elif len(errors_resp) > 1:
            LOG.error(f"Multiple errors occurred: {errors_resp}")
            raise Exception(f"Multiple errors occurred: {errors_resp}")
        return doi_data
